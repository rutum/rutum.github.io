<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="http://localhost:4000/assets/images/lightning-border.png">
<title>Build your own search Engine | Rutu Mulkar</title>

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Build your own search Engine | Rutu Mulkar</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Build your own search Engine" />
<meta name="author" content="rutum" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this post, I will take you through the steps for calculating the $tf \times idf$ values for all the words in a given document. To implement this, we use a small dataset (or corpus, as NLPers like to call it) form the Project Gutenberg Catalog. This is just a simple toy example on a very small dataset. In real life we use much larger corpora, and need some more sophisticated tools in order to handle large amounts of data. To brush up on the basic concepts of $tf \times idf$ you might want to check out my post on the The Math behind Lucene." />
<meta property="og:description" content="In this post, I will take you through the steps for calculating the $tf \times idf$ values for all the words in a given document. To implement this, we use a small dataset (or corpus, as NLPers like to call it) form the Project Gutenberg Catalog. This is just a simple toy example on a very small dataset. In real life we use much larger corpora, and need some more sophisticated tools in order to handle large amounts of data. To brush up on the basic concepts of $tf \times idf$ you might want to check out my post on the The Math behind Lucene." />
<link rel="canonical" href="http://localhost:4000/blog/2014/build-your-own-search-engine/" />
<meta property="og:url" content="http://localhost:4000/blog/2014/build-your-own-search-engine/" />
<meta property="og:site_name" content="Rutu Mulkar" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2014-05-20T00:00:00-07:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Build your own search Engine" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"rutum"},"description":"In this post, I will take you through the steps for calculating the $tf \\times idf$ values for all the words in a given document. To implement this, we use a small dataset (or corpus, as NLPers like to call it) form the Project Gutenberg Catalog. This is just a simple toy example on a very small dataset. In real life we use much larger corpora, and need some more sophisticated tools in order to handle large amounts of data. To brush up on the basic concepts of $tf \\times idf$ you might want to check out my post on the The Math behind Lucene.","@type":"BlogPosting","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"},"name":"rutum"},"headline":"Build your own search Engine","dateModified":"2014-05-20T00:00:00-07:00","datePublished":"2014-05-20T00:00:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2014/build-your-own-search-engine/"},"url":"http://localhost:4000/blog/2014/build-your-own-search-engine/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Lato:wght@100;300;&family=Mukta:wght@300;500&family=Roboto:wght@100;300&display=swap" rel="stylesheet">
<link href="/assets/css/screen.css" rel="stylesheet">

<link href="/assets/css/main.css" rel="stylesheet">

<script src="/assets/js/jquery.min.js"></script>

<!-- Google analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-31232401-1', 'auto');
ga('send', 'pageview');
</script>
<style>
    ::-moz-selection { /* Code for Firefox */
        color: #fbfff1;
        background: #3066be;
    }
    
    ::selection {
        color: #fbfff1;
        background: #3066be;
    }
    </style>

</head>

<!--  -->


<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<!-- <link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet"> -->
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	</noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="http://localhost:4000/"> 
        <h2> <img class="d-inline-block align-text-center" src="http://localhost:4000/assets/images/lightning.png"/></h2>
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">
        <!-- Begin Menu -->
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                <a class="nav-link" href="/index.html">Syntax and Semantics</a>
                </li>
                <li class="nav-item">
                     <a class="nav-link" href="/books/index.html"> Book Summaries</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/_pages/about/index.html">About</a>
                </li>
                <li class="nav-item">
                    <script src="/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search f-dlex" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<!-- <form class="d-flex">
    <input class="form-control me-2" type="search" placeholder="Search" aria-label="Search">
    <button class="btn btn-outline-success" type="submit">Search</button>
  </form> -->
  
<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="/assets/js/lunrsearchengine.js"></script>
                </li>
            </ul>
        <!-- End Menu -->
    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->


<div class="site-content">

    <div class="container">

        <!-- Site Title
        ================================================== -->
        <div class="mainheading">
        <!--     <h1 class="sitetitle">Rutu Mulkar</h1>
            <p class="lead">
                
            </p> -->
        </div>
        <!-- Content
        ================================================== -->

        <div class="main-content">
            <!-- reading progress-bar -->
<div class="progress_container">
    <progress class="progress_read" id="myBar" value="0"></progress>
</div>

<!-- Begin Article
    ================================================== -->
    <div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-1 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=Build your own search Engine&url=http://localhost:4000/blog/2014/build-your-own-search-engine/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=http://localhost:4000/blog/2014/build-your-own-search-engine/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/blog/2014/build-your-own-search-engine/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

    </ul>
    
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
    
</div>

        </div>

        <!-- Post -->
        <!--  -->

        <div class="col-md-8 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Post Title -->
                <h1 class="posttitle">Build your own search Engine</h1>
                <!-- Reading time -->
                <!-- <span class="bluecolor smtext" title="Estimated read time">
    
    
        Approximate time to read: 6 min
    
</span> -->
            </div>
            <!-- Post Date -->
            <p>
                <span class="post-date"><time class="post-date" datetime="2014-05-20">May 20th, 2014</time> </span>            
                <br>
                <span>
                    <span class="tag"><a href="http://localhost:4000/categories#"> information retrieval</a></span>
                
                    <span class="tag"><a href="http://localhost:4000/categories#"> lucene</a></span>
                </span> 

            </p>
            
            

            <!-- Rating -->
            <!--  -->
            
            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <p>In this post, I will take you through the steps for calculating the $tf \times idf$ values for all the words in a given document. To implement this, we use a small dataset (or corpus, as NLPers like to call it) form the <a href="http://www.gutenberg.org/">Project Gutenberg Catalog</a>. This is just a simple toy example on a very small dataset. In real life we use much larger corpora, and need some more sophisticated tools in order to handle large amounts of data. To brush up on the basic concepts of $tf \times idf$ you might want to check out my post on the <a href="../core-of-lucene/index.html">The Math behind Lucene</a>.</p>

<p>For this exercise, we will use the <a href="http://www.gutenberg.org/">Project Gutenberg Selections</a> which are released as part of <a href="http://nltk.googlecode.com/svn/trunk/nltk_data/index.xml">NLTK Data</a>. NLTK - Natural Language Toolkit - is a python based module for text processing. The corpus - Project Gutenberg Selections - contains 18 files. Each file is a complete book. Our task is to calculate the $tf \times idf$ of all the words for each of the documents provided. In the end of this exercise we will have 18 documents, with the $tf \times idf$ of each word in each of the documents.</p>

<p>Documents with $tf \times idf$ values for each word (or token) are often used (with the <a href="http://en.wikipedia.org/wiki/Vector_space_model">vector space model</a>) to compute the similarity between two documents. Such statistics are quite relevant in Information Retrieval, Search Engines, Document Similarity, and so on.</p>

<blockquote>
  <p>NOTE: All the materials needed for this exercise (code + data) can be downloaded from my <a href="https://github.com/rutum/tf-idf">github repo</a>.</p>
</blockquote>

<p>The code is written in perl, and is heavy in regular expressions. I have tried my best to document the code, but if you have any issues, or discover bugs, please do not hesitate in contacting me. I will not go into the details of all my code in this post, but will highlight a few features.</p>

<p>This is one of the most important tasks of any NLP application. Discourse often contains non-ascii characters, no alphanumeric characters, spaces, and so on. The first and most important task is to remove these unwanted characters from text, to clean it up. Here is a set of regular expressions (regex) that is helpful for this dataset. However it is not an exhaustive set of regexes. For instance, I have not used any regex to convert <a href="http://en.wikipedia.org/wiki/UTF-8">UTF8</a> to <a href="http://en.wikipedia.org/wiki/ASCII">ASCII</a>.</p>

<figure class="highlight"><pre><code class="language-perl" data-lang="perl"><span class="nv">def</span> <span class="nv">test</span><span class="p">():</span>
            <span class="c1">#remove endline character</span>
            <span class="nb">chomp</span><span class="p">(</span><span class="nv">$txt</span><span class="p">);</span>
            <span class="c1">#remove extra space characters</span>
            <span class="nv">$txt</span> <span class="o">=~</span> <span class="sr">s/[\h\v]+/ /g</span><span class="p">;</span>
            <span class="c1">#remove caps</span>
            <span class="nv">$txt</span> <span class="o">=~</span> <span class="sr">tr/[A-Z]/[a-z]/</span><span class="p">;</span>
            <span class="c1">#remove non-alphanumeric characters</span>
            <span class="nv">$txt</span> <span class="o">=~</span> <span class="sr">s/[^a-zA-Z\d\s]//g</span><span class="p">;</span></code></pre></figure>

<p>The rest of my code can be downloaded from my <a href="https://github.com/rutum/tf-idf">github repo</a>. The code is relatively easy to understand if you are familiar with regular expressions, and understand perl. I have provided my solutions in the output directory, within the folder $tf \times idf$. The intermediate $tf$ and $idf$ results are also provided in the output folder.</p>

<p>It is interesting to note here that words occurring in all the documents have an idf value of 0. This means that their tf*idf value will also be 0, deeming them insignificant in contributing to the document vector. These include words like - a, the, when, if, etc. A longer list can be developed by sorting all the values in the file idf.txt (downloaded from my <a href="https://github.com/rutum/tf-idf">github repo</a>).</p>

<p>The next step, is to use these metrics to compute document similarity. Discovering similar document in a corpus of documents remains one of the most important problems of information retrieval. This is often done by converting documents into document vectors, and comparing the similarity of these vectors to each other using vector similarity metrics.</p>

<p>Note: All the code for this can be downloaded from my <a href="https://github.com/rutum/document_similarity">github repo</a>.</p>

<p>This post uses the output generated in the toy example for $tf \times idf$ which is available in this <a href="https://github.com/rutum/document_similarity">github repo</a>.</p>

<p>CREATING DOCUMENT VECTORS</p>

<p>After computing the $tf \times idf$ values for each document in a given corpus, we need to go through the exercise to convert these values into a document vector. If you recall some vector basics, a vector constitutes a magnitude and a direction. In our case, the direction is represented by a word in the document and magnitude is the weight or the $tf \times idf$ value of the word in the document. In order to simplify our vector calculations we pre-specify the locations of each word in the array representing the document, creating a sparse vector.</p>

<p>For instance consider the vocabulary of the entire corpus to be:
<em>John, Mary, Susan, Kendra, sang, for, with, plays</em></p>

<p>We will assign a location to each word in the vocabulary as:</p>

<table>
  <tbody>
    <tr>
      <td>John</td>
      <td>Mary</td>
      <td>Susan</td>
      <td>Kendra</td>
      <td>sang</td>
      <td>for</td>
      <td>with</td>
      <td>dances</td>
    </tr>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>3</td>
      <td>4</td>
      <td>5</td>
      <td>6</td>
      <td>7</td>
    </tr>
  </tbody>
</table>

<p>Given this data, for the sentence: John sang for Mary, we create the following boolean document vector:</p>

<table>
  <tbody>
    <tr>
      <td>John</td>
      <td>Mary</td>
      <td>Susan</td>
      <td>Kendra</td>
      <td>sang</td>
      <td>for</td>
      <td>with</td>
      <td>dances</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>Here a 1 represents the existence of a word in the text, and a 0 represents the absence of a word from the text. This example is simply to illustrate the concept of creating a document vector. In our toy example we will replace with 1 values with the tf*idf values of a given word in the given document.</p>

<p>Computing the dot Product of two Vectors</p>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td>John</td>
      <td>Mary</td>
      <td>Kendra</td>
      <td>sang</td>
      <td>for</td>
      <td>with</td>
      <td>dances</td>
      <td>Sentence</td>
    </tr>
    <tr>
      <td>d1</td>
      <td>0</td>
      <td>0.27</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>John dances with Mary.</td>
    </tr>
    <tr>
      <td>d2</td>
      <td>0</td>
      <td>0</td>
      <td>0.1</td>
      <td>0.27</td>
      <td>0.27</td>
      <td>0</td>
      <td>0</td>
      <td>John sang for Kendra.</td>
    </tr>
    <tr>
      <td>d3</td>
      <td>0</td>
      <td>0</td>
      <td>0.1</td>
      <td>0</td>
      <td>0</td>
      <td>0.1</td>
      <td>0.1</td>
      <td>John dances with Kendra.</td>
    </tr>
  </tbody>
</table>

<p>dot product between d1 and d2:</p>

\[d1 \cdot d2 = d1.John * d2.John + d1.Mary * d2.Mary + ....\]

<p>The final similarity scores are:</p>

<table>
  <tbody>
    <tr>
      <td>doc3.txt</td>
      <td>doc2.txt</td>
      <td>0.178554901188263</td>
    </tr>
    <tr>
      <td>doc3.txt</td>
      <td>doc1.txt</td>
      <td>0.377800203993898</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>doc2.txt</td>
      <td>doc3.txt</td>
      <td>0.178554901188263</td>
    </tr>
    <tr>
      <td>doc2.txt</td>
      <td>doc1.txt</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>doc1.txt</td>
      <td>doc3.txt</td>
      <td>0.377800203993898</td>
    </tr>
    <tr>
      <td>doc1.txt</td>
      <td>doc2.txt</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>Notice that document 1 is most similar to document 3. Document 2 and document 1 have absolutely no similarities. This is because both these documents have just one word in common - <em>John</em>, which is common to all the documents, so has a weight of 0.</p>

<p>The code is documented, and can be downloaded from my <a href="https://github.com/rutum/document_similarity">github repo</a>.</p>

<p>Happy Coding!</p>

            </div>
        </div>
        <!-- End Post -->

        <!-- Related posts list-->
        <aside class="col-md-3 flex-md-unordered">
            <div class="related-posts sticky-top sticky-top-offset">
    <p class="related">Related posts:</p>
    <ul>
        
            
                
                    <li><a href="/blog/2023/ml-to-llm/">Machine Learning, Deep Learning and Large Language Models</a></li>
                
            
        
            
                
                    <li><a href="/blog/2023/Important-books-for-AI/">Important books to read for AI</a></li>
                
            
        
            
                
                    <li><a href="/blog/2021/probability-theory/">Probability Theory for Natural Language Processing</a></li>
                
            
        
            
                
                    <li><a href="/blog/2021/language-models/">The Foundations of Language Models</a></li>
                
            
        
            
                
                    <li><a href="/blog/2021/logistic-regression/">The Comprehensive Guide to Logistic Regression</a></li>
                
            
        
            
                
                    <li><a href="/blog/2021/byte-pair-encoding/">What is Byte-Pair Encoding for Tokenization?</a></li>
                
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
                
                    <li><a href="/blog/2019/manageml/">Managing Machine Learning Experiments</a></li>
                
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
                
                    <li><a href="/blog/2017/what-is-nlp/">What is Natural Language Processing (NLP)?</a></li>
                
            
        
            
                
                    <li><a href="/blog/2016/NLP-ML/">Natural Language Processing vs. Machine Learning vs. Deep Learning</a></li>
                
            
        
            
                
                    <li><a href="/blog/2015/word2vec/">Online Word2Vec for Gensim</a></li>
                
            
        
            
                
                    <li><a href="/blog/2015/statistics-for-everyone/">Understanding your Data - Basic Statistics</a></li>
                
            
        
            
                
                    <li><a href="/blog/2014/all-about-that-bayes-intro-to-probability/">An Introduction to Probability</a></li>
                
            
        
            
                
                    <li class="active"><a href="/blog/2014/build-your-own-search-engine/">Build your own search Engine</a></li>
                
            
        
            
                
                    <li><a href="/blog/2014/core-of-lucene/">The Math behind Lucene</a></li>
                
            
        
    </ul>
</div>
        </aside>

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

    <div class="container">
        <div id="comments" class="row justify-content-center mb-5">
            <div class="col-md-8">
                <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'datasciencetoolbox'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

            </div>
        </div>
    </div>

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->



<script>
    // Load document before calculating window height
            var winHeight = $(window).height(),
                docHeight = $(document).height(),
                progressBar = $('#myBar'),
                max, value;

            /* Set the max scrollable area */
            max = docHeight - winHeight;
            //progressBar.attr('max', max);

            $(document).on('scroll', function () {
                value = $(window).scrollTop()/max;
                console.log(value);
                progressBar.attr('value', value);
            });
</script>
        </div>
    </div>

    <!-- Begin Footer
    ================================================== -->
    <footer class="footer">
        <div class="container">
            <div class="row">
                <div class="col-md-12 col-sm-12 text-center text-lg-center">
                    Copyright © 2023 Rutu Mulkar. All Rights Reserved.
                </div>
            </div>
        </div>
    </footer>
    <!-- End Footer
    ================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="/assets/js/mediumish.js"></script>



<script src="/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//datasciencetoolbox.disqus.com/count.js"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: 
        {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: false,
        }
        
    });
</script>

  
<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    CommonHTML: { linebreaks: { automatic: true } },
    "HTML-CSS": { scale: 100, linebreaks: { automatic: true } },
    TeX: { equationNumbers: {autoNumber: "all"} } });
</script>

<!-- Category filter -->
<script src="/assets/js/categorySearch.js"></script>
</body>
</html>
