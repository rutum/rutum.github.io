<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="http://localhost:4000/assets/images/lightning-border.png">
<title>The Math behind Lucene | Rutu Mulkar</title>

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>The Math behind Lucene | Rutu Mulkar</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="The Math behind Lucene" />
<meta name="author" content="rutum" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Lucene is an open source search engine, that one can use on top of custom data and create your own search engine - like your own personal google. In this post, we will go over the basic math behind Lucene, and how it ranks documents to the input search query." />
<meta property="og:description" content="Lucene is an open source search engine, that one can use on top of custom data and create your own search engine - like your own personal google. In this post, we will go over the basic math behind Lucene, and how it ranks documents to the input search query." />
<link rel="canonical" href="http://localhost:4000/blog/2014/core-of-lucene/" />
<meta property="og:url" content="http://localhost:4000/blog/2014/core-of-lucene/" />
<meta property="og:site_name" content="Rutu Mulkar" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2014-04-20T00:00:00-07:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="The Math behind Lucene" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"rutum"},"description":"Lucene is an open source search engine, that one can use on top of custom data and create your own search engine - like your own personal google. In this post, we will go over the basic math behind Lucene, and how it ranks documents to the input search query.","@type":"BlogPosting","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"},"name":"rutum"},"headline":"The Math behind Lucene","dateModified":"2014-04-20T00:00:00-07:00","datePublished":"2014-04-20T00:00:00-07:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2014/core-of-lucene/"},"url":"http://localhost:4000/blog/2014/core-of-lucene/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Lato:wght@100;300;&family=Mukta:wght@300;500&family=Roboto:wght@100;300&display=swap" rel="stylesheet">
<link href="/assets/css/screen.css" rel="stylesheet">

<link href="/assets/css/main.css" rel="stylesheet">

<script src="/assets/js/jquery.min.js"></script>

<!-- Google analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-31232401-1', 'auto');
ga('send', 'pageview');
</script>
<style>
    ::-moz-selection { /* Code for Firefox */
        color: #fbfff1;
        background: #3066be;
    }
    
    ::selection {
        color: #fbfff1;
        background: #3066be;
    }
    </style>

</head>

<!--  -->


<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<!-- <link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet"> -->
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	</noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="http://localhost:4000/"> 
        <h2> <img class="d-inline-block align-text-center" src="http://localhost:4000/assets/images/lightning.png"/></h2>
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">
        <!-- Begin Menu -->
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                <a class="nav-link" href="/index.html">Syntax and Semantics</a>
                </li>
                <li class="nav-item">
                     <a class="nav-link" href="/books/index.html"> Book Summaries</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/_pages/about/index.html">About</a>
                </li>
                <li class="nav-item">
                    <script src="/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search f-dlex" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<!-- <form class="d-flex">
    <input class="form-control me-2" type="search" placeholder="Search" aria-label="Search">
    <button class="btn btn-outline-success" type="submit">Search</button>
  </form> -->
  
<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="/assets/js/lunrsearchengine.js"></script>
                </li>
            </ul>
        <!-- End Menu -->
    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->


<div class="site-content">

    <div class="container">

        <!-- Site Title
        ================================================== -->
        <div class="mainheading">
        <!--     <h1 class="sitetitle">Rutu Mulkar</h1>
            <p class="lead">
                
            </p> -->
        </div>
        <!-- Content
        ================================================== -->

        <div class="main-content">
            <!-- reading progress-bar -->
<div class="progress_container">
    <progress class="progress_read" id="myBar" value="0"></progress>
</div>

<!-- Begin Article
    ================================================== -->
    <div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-1 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=The Math behind Lucene&url=http://localhost:4000/blog/2014/core-of-lucene/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=http://localhost:4000/blog/2014/core-of-lucene/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/blog/2014/core-of-lucene/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

    </ul>
    
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
    
</div>

        </div>

        <!-- Post -->
        <!--  -->

        <div class="col-md-8 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Post Title -->
                <h1 class="posttitle">The Math behind Lucene</h1>
                <!-- Reading time -->
                <!-- <span class="bluecolor smtext" title="Estimated read time">
    
    
        Approximate time to read: 6 min
    
</span> -->
            </div>
            <!-- Post Date -->
            <p>
                <span class="post-date"><time class="post-date" datetime="2014-04-20">Apr 20th, 2014</time> </span>            
                <br>
                <span>
                    <span class="tag"><a href="http://localhost:4000/categories#"> information retrieval</a></span>
                
                    <span class="tag"><a href="http://localhost:4000/categories#"> search</a></span>
                
                    <span class="tag"><a href="http://localhost:4000/categories#"> lucene</a></span>
                </span> 

            </p>
            
            

            <!-- Rating -->
            <!--  -->
            
            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <p><a href="https://lucene.apache.org/">Lucene</a> is an open source search engine, that one can use on top of custom data and create your own search engine - like your own personal google. In this post, we will go over the basic math behind Lucene, and how it ranks documents to the input search query.</p>

<p>THE BASICS - TF*IDF</p>

<p>The analysis of language often brings us in situations where we are required to determine the weight or importance of a given word in a document, to determine the relative importance or similarity of a document to another document. In situations such as this, the first step to remove <a href="http://en.wikipedia.org/wiki/Stop_words">stop words</a> which are basically words that dont contribute to the general focus of a given article. Most common stop words are words like - <em>a</em>, <em>when</em>, <em>who</em>, <em>what</em>. The list of stop words keeps changing based on the domain of discourse. For instance, in a corpus of articles about the human heart, the word heart could potentially be a stop word due to the sheer frequency in which it is mentioned. It is always a good idea to remove stop words in a given text before processing it. However, once these stop words are removed, one still faces the task of determining the relative importance or weights of the remaining words in the document - lets start talking about <a href="http://en.wikipedia.org/wiki/Tf*idf">tf-idf</a>.</p>

<p>Observing the words in a document, an intuitive way to discover the importance of a given word is to count the frequency of the word in the document. This is the Term Frequency or the tf of the word in the given document. tf is often normalized so as to not introduce a bias because of the document size. A normalized tf for a given word in a given document is calculated as:</p>

\[tf_{w,d} = \frac{C_{w,d}}{\sum C_{w,d}}\]

<p>where, \(C_{w,d}\) is the word count of word \(w\) in document \(d\) and $\sum C_{w,d}$ is the total count of all words \(w\) in document $d$.</p>

<p>However, $tf$ by itself is not enough to capture the importance of a word in a document, as there are numerous words like <em>a</em>, <em>the</em>, <em>with</em>, <em>however</em>, that have a very high frequency, but less importance. So we need to complement this  with the <em>Document Frequency</em> of each word - or $df$. Document Frequency is the total number of documents a given word occurs in. If a word occurs in a large number of documents, it has a high $df$. When this $df$ is used to scale the weight of a word in the document, it is called $idf$ or <em>Inverse Document Frequency</em> of that given word.</p>

<p>If $N$ is the total number of documents in a given corpus, then the $IDF$ of a given word in the corpus is:</p>

\[idf_w = log \frac{N}{df_w}\]

<p>Notice that $tf$ is calculated for a given word in a given document, $IDF$ is calculated for a given word over all the documents.</p>

<p>Once we have the $tf$ and $idf$, we can calculate the $tf \times idf$ score for each word to determine the weight of a word in the given document.</p>

<p>The score $tf_w \times idf_{w,d}$ assigns each word $w$ a weight in document. Here are some insights about it.</p>
<ul>
<li>$tf_w \times idf_{w,d}$ is highest when w occurs many times within a small number of documents. This means that the word is significant, and can help establish relevance within the small number of documents.</li>
<li>$tf_w \times idf_{w,d}$ is lower when the word occurs fewer times in a document, or occurs in many documents. If a word occurs infrequently, it might not be of significance. Similarly if a word occurs in a very large number of documents, it probably will not help in discriminating between the document.</li>
<li>$tf_w \times idf_{w,d}$ is lowest when the term occurs in virtually all documents. This covers words like *a*, *an* *the*, *when* etc. which span a large number of documents and have no contribution towards the semantic composition of the document.</li>
</ul>

<p>FROM TF*IDF TO DOCUMENT SIMILARITY</p>

<p>Document vectors are created by computing the relative weights of each word in the document. One way to accomplish this is by computing the $tf \times idf$ values of each of the words in the document. When we compute the $tf \times idf$ of each of the words in a document, we end up with documents with a list of features (words) with their values (weights). In a sense, this represents the document vector. The representation of documents as vectors in a common vector space is known as a <em>vector space model</em>, and is the basis of a large number of information retrieval tasks.</p>

<p>A standard way of computing the document similarity is to compute the cosine similarity of the vector representations of the documents. If $d_1$ and $d_2$ are two documents, and $V(d_1)$ and $V(d_2)$ are the vector representations of them respectively, then the similarity of $d_1$ and $d_2$ can be measured as the cosine of the angle between $V(d_1)$ and $V(d_2)$</p>

\[sim(d_1, d_2) = \frac{V(d_1) \cdot V(d_2)}{\mid V(d_1) \mid \mid V(d_2) \mid}\]

<p>In this equation, the numerator is the dot product of vectors $V(d1)$ and $V(d2)$, and the denominator is the product of the <em>Euclidean length</em>. Euclidean Length is the sum of squares of the magnitude of each element of the vector.</p>

<p>If $V(d_1)$ and $V(d_2)$ are the following,</p>

\[V(d_1) = [a_1, a_2, a_3, a_4 ...]\]

\[V(d_2) = [b_1, b_2, b_3, b_4 ...]\]

<p>The dot product of $V(d_1)$ and $V(d_2)$ is:</p>

\[V(d_1) . V(d_2) = a_1b_1 + a_2b_2 + a_3b_3 + a_4b_4 + ...\]

<p>The Euclidean length of $V(d_1)$:</p>

\[\sqrt{a_1^2 +  a_2^2 + a_3^2 + a_4^2 + ... }\]

<p>Similarly, the Euclidean length of $V(d_2)$:</p>

\[\sqrt{b_1^2 +  b_2^2 + b_3^2 + b_4^2 + ... }\]

<p>Applying (6), (7) and (8) to (3) we get:</p>

\[sim(d_1, d_2) = \frac{a_1b_1 + a_2b_2 + a_3b_3 + a_4b_4 + ...)}{\sqrt{a_1^2 +  a_2^2 + a_3^2 + a_4^2 + ... } \sqrt{b_1^2 +  b_2^2 + b_3^2 + b_4^2 + ... }}\]

<p>Ok, we have cosine similarity. Now what?
What Cosine similarity tells us, is how similar 2 documents are. If the documents are very similar, we have the similarity score closer to 1, but if the documents are completely different, the similarity score is closer to -1.</p>

<p>This is the heart of the scoring mechanism that Lucene uses to retrieve similar documents given a search query. Although Lucene does use a couple of other (mostly user defined) constants to fine tune the results, $tf \times idf$ is the heart of how Lucene operates.</p>

<p><strong>References:</strong></p>

<ol>
  <li>Introduction to Information Retrieval, by Christopher D. Manning, Prabhakar Raghavan &amp; Hinrich Schütze, <a href="http://nlp.stanford.edu/IR-book/html/htmledition/scoring-term-weighting-and-the-vector-space-model-1.html">Chapter on Scoring, term weighting and the vector space model</a></li>
  <li><a href="http://www.ir-facility.org/scoring-and-ranking-techniques-tf-idf-term-weighting-and-cosine-similarity">Information Retrieval Facility</a></li>
</ol>

            </div>
        </div>
        <!-- End Post -->

        <!-- Related posts list-->
        <aside class="col-md-3 flex-md-unordered">
            <div class="related-posts sticky-top sticky-top-offset">
    <p class="related">Related posts:</p>
    <ul>
        
            
                
                    <li><a href="/blog/2023/ml-to-llm/">Machine Learning, Deep Learning and Large Language Models</a></li>
                
            
        
            
                
                    <li><a href="/blog/2023/Important-books-for-AI/">Important books to read for AI</a></li>
                
            
        
            
                
                    <li><a href="/blog/2021/probability-theory/">Probability Theory for Natural Language Processing</a></li>
                
            
        
            
                
                    <li><a href="/blog/2021/language-models/">The Foundations of Language Models</a></li>
                
            
        
            
                
                    <li><a href="/blog/2021/logistic-regression/">The Comprehensive Guide to Logistic Regression</a></li>
                
            
        
            
                
                    <li><a href="/blog/2021/byte-pair-encoding/">What is Byte-Pair Encoding for Tokenization?</a></li>
                
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
                
                    <li><a href="/blog/2019/manageml/">Managing Machine Learning Experiments</a></li>
                
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
                
                    <li><a href="/blog/2017/what-is-nlp/">What is Natural Language Processing (NLP)?</a></li>
                
            
        
            
                
                    <li><a href="/blog/2016/NLP-ML/">Natural Language Processing vs. Machine Learning vs. Deep Learning</a></li>
                
            
        
            
                
                    <li><a href="/blog/2015/word2vec/">Online Word2Vec for Gensim</a></li>
                
            
        
            
                
                    <li><a href="/blog/2015/statistics-for-everyone/">Understanding your Data - Basic Statistics</a></li>
                
            
        
            
                
                    <li><a href="/blog/2014/all-about-that-bayes-intro-to-probability/">An Introduction to Probability</a></li>
                
            
        
            
                
                    <li><a href="/blog/2014/build-your-own-search-engine/">Build your own search Engine</a></li>
                
            
        
            
                
                    <li class="active"><a href="/blog/2014/core-of-lucene/">The Math behind Lucene</a></li>
                
            
        
    </ul>
</div>
        </aside>

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

    <div class="container">
        <div id="comments" class="row justify-content-center mb-5">
            <div class="col-md-8">
                <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'datasciencetoolbox'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

            </div>
        </div>
    </div>

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->



<script>
    // Load document before calculating window height
            var winHeight = $(window).height(),
                docHeight = $(document).height(),
                progressBar = $('#myBar'),
                max, value;

            /* Set the max scrollable area */
            max = docHeight - winHeight;
            //progressBar.attr('max', max);

            $(document).on('scroll', function () {
                value = $(window).scrollTop()/max;
                console.log(value);
                progressBar.attr('value', value);
            });
</script>
        </div>
    </div>

    <!-- Begin Footer
    ================================================== -->
    <footer class="footer">
        <div class="container">
            <div class="row">
                <div class="col-md-12 col-sm-12 text-center text-lg-center">
                    Copyright © 2023 Rutu Mulkar. All Rights Reserved.
                </div>
            </div>
        </div>
    </footer>
    <!-- End Footer
    ================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="/assets/js/mediumish.js"></script>



<script src="/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//datasciencetoolbox.disqus.com/count.js"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: 
        {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: false,
        }
        
    });
</script>

  
<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    CommonHTML: { linebreaks: { automatic: true } },
    "HTML-CSS": { scale: 100, linebreaks: { automatic: true } },
    TeX: { equationNumbers: {autoNumber: "all"} } });
</script>

<!-- Category filter -->
<script src="/assets/js/categorySearch.js"></script>
</body>
</html>
