<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="http://localhost:4000/assets/images/lightning-border.png">
<title>What is Byte-Pair Encoding for Tokenization? | Rutu Mulkar</title>

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>What is Byte-Pair Encoding for Tokenization? | Rutu Mulkar</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="What is Byte-Pair Encoding for Tokenization?" />
<meta name="author" content="rutum" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Tokenization is the concept of dividing text into tokens - words (unigrams), or groups of words (n-grams) or even characters. Morphology traditionally defines morphemes as the smallest semantic unit. e.g. The word Unfortunately can be broken down as un - fortun - ate - ly" />
<meta property="og:description" content="Tokenization is the concept of dividing text into tokens - words (unigrams), or groups of words (n-grams) or even characters. Morphology traditionally defines morphemes as the smallest semantic unit. e.g. The word Unfortunately can be broken down as un - fortun - ate - ly" />
<link rel="canonical" href="http://localhost:4000/blog/2021/byte-pair-encoding/" />
<meta property="og:url" content="http://localhost:4000/blog/2021/byte-pair-encoding/" />
<meta property="og:site_name" content="Rutu Mulkar" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-01-28T00:00:00-08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="What is Byte-Pair Encoding for Tokenization?" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"rutum"},"description":"Tokenization is the concept of dividing text into tokens - words (unigrams), or groups of words (n-grams) or even characters. Morphology traditionally defines morphemes as the smallest semantic unit. e.g. The word Unfortunately can be broken down as un - fortun - ate - ly","@type":"BlogPosting","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"},"name":"rutum"},"headline":"What is Byte-Pair Encoding for Tokenization?","dateModified":"2021-01-28T00:00:00-08:00","datePublished":"2021-01-28T00:00:00-08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2021/byte-pair-encoding/"},"url":"http://localhost:4000/blog/2021/byte-pair-encoding/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Lato:wght@100;300;&family=Mukta:wght@300;500&family=Roboto:wght@100;300&display=swap" rel="stylesheet">
<link href="/assets/css/screen.css" rel="stylesheet">

<link href="/assets/css/main.css" rel="stylesheet">

<script src="/assets/js/jquery.min.js"></script>

<!-- Google analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-31232401-1', 'auto');
ga('send', 'pageview');
</script>
<style>
    ::-moz-selection { /* Code for Firefox */
        color: #fbfff1;
        background: #3066be;
    }
    
    ::selection {
        color: #fbfff1;
        background: #3066be;
    }
    </style>

</head>

<!--  -->


<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<!-- <link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet"> -->
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	</noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="http://localhost:4000/"> 
        <h2> <img class="d-inline-block align-text-center" src="http://localhost:4000/assets/images/lightning.png"/></h2>
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">
        <!-- Begin Menu -->
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                <a class="nav-link" href="/index.html">Syntax and Semantics</a>
                </li>
                <li class="nav-item">
                     <a class="nav-link" href="/books/index.html"> Book Summaries</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/_pages/about/index.html">About</a>
                </li>
                <li class="nav-item">
                    <script src="/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search f-dlex" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<!-- <form class="d-flex">
    <input class="form-control me-2" type="search" placeholder="Search" aria-label="Search">
    <button class="btn btn-outline-success" type="submit">Search</button>
  </form> -->
  
<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="/assets/js/lunrsearchengine.js"></script>
                </li>
            </ul>
        <!-- End Menu -->
    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->


<div class="site-content">

    <div class="container">

        <!-- Site Title
        ================================================== -->
        <div class="mainheading">
        <!--     <h1 class="sitetitle">Rutu Mulkar</h1>
            <p class="lead">
                
            </p> -->
        </div>
        <!-- Content
        ================================================== -->

        <div class="main-content">
            <!-- reading progress-bar -->
<div class="progress_container">
    <progress class="progress_read" id="myBar" value="0"></progress>
</div>

<!-- Begin Article
    ================================================== -->
    <div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-1 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=What is Byte-Pair Encoding for Tokenization?&url=http://localhost:4000/blog/2021/byte-pair-encoding/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=http://localhost:4000/blog/2021/byte-pair-encoding/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/blog/2021/byte-pair-encoding/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

    </ul>
    
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
    
</div>

        </div>

        <!-- Post -->
        <!--  -->

        <div class="col-md-8 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Post Title -->
                <h1 class="posttitle">What is Byte-Pair Encoding for Tokenization?</h1>
                <!-- Reading time -->
                <!-- <span class="bluecolor smtext" title="Estimated read time">
    
    
        Approximate time to read: 3 min
    
</span> -->
            </div>
            <!-- Post Date -->
            <p>
                <span class="post-date"><time class="post-date" datetime="2021-01-28">Jan 28th, 2021</time> </span>            
                <br>
                <span>
                    <span class="tag"><a href="http://localhost:4000/categories#"> tokenization</a></span>
                </span> 

            </p>
            
            

            <!-- Rating -->
            <!--  -->
            
            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <p>Tokenization is the concept of dividing text into tokens - words (unigrams), or groups of words (n-grams) or even characters. 
Morphology traditionally defines morphemes as the smallest semantic unit. e.g. The word <strong>Unfortunately</strong> can be broken down as <strong>un - fortun - ate - ly</strong></p>

<p>[[un [[fortun(e) ]\(_{ROOT}\) ate]\(_{STEM}\)]\(_{STEM}\) ly]\(_{WORD}\)</p>

<p>Morphology is little studied with deep learning, but Byte Pair Encoding is a way to infer morphology from text. Byte-pair encoding allows us to define tokens automatically from data, instead of precpecifying character or word boundaries. This is especially useful in dealing with unkown words.</p>

<h2 id="modern-tokenizers">Modern Tokenizers</h2>

<p>Modern tokenizers often automatically induce tokens that include tokens smaller than words - called <strong>Subwords</strong>. E.g. the subwords “-ly”, “-ing” give us an ideal about the type of the word - which is what subword tokenization aims to do.</p>

<p>Most tokenizers have two parts:</p>
<ol>
  <li><strong>A token learner:</strong> takes a raw training corpus and indices a vocabulary - a set of tokens.</li>
  <li><strong>A token segmenter:</strong> takes a raw test sentence and segments it into the tokens in the vocabulary.</li>
</ol>

<p>Three algorithms are widely used :</p>
<ol>
  <li>Byte Pair Encoding (Sennrick et. al 2016)</li>
  <li>Unigram Language Modeling (Kudo 2018)</li>
  <li>Wordpiece (Schuster and Nakajima 2012) and Sentencepiece (Kudo and Richardson, 2018)</li>
</ol>

<p>Byte Pair Encoding (BPE) is the simplest of the three.</p>

<h2 id="byte-pair-encoding-bpe-algorithm">Byte Pair Encoding (BPE) Algorithm</h2>

<p>BPE runs within word boundaries. <strong><em>BPE Token Learning</em></strong> begins with a vocabulary that is just the set of individual characters (tokens). It then runs over a training corpus ‘k’ times and each time, it merges 2 tokens that occur the most frequently in text. e.g. ‘e’ and ‘r’ are merged into a single token ‘er’ when they occur together in the same order.</p>

<p>At the end of ‘k’ iterations, the algorithm produces a list of most frequent ‘k’ tokens along with the original set of characters.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">byte_pair_encoding</span><span class="p">(</span><span class="n">string_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">vocab</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
	 <span class="n">vocab</span> <span class="o">=</span> <span class="o">&lt;</span><span class="nb">list</span> <span class="n">of</span> <span class="n">unique</span> <span class="n">characters</span> <span class="ow">in</span> <span class="n">string_list</span><span class="o">&gt;</span>
	 <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
	 	<span class="n">c_left</span><span class="p">,</span> <span class="n">c_right</span> <span class="o">=</span> <span class="n">most</span> <span class="n">frequent</span> <span class="n">pair</span> <span class="n">of</span> <span class="n">adjacent</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="n">string_list</span>
	 	<span class="n">c_new</span> <span class="o">=</span> <span class="n">c_left</span> <span class="o">+</span> <span class="n">c_right</span> <span class="c1"># create a new bigram
</span>	 	<span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span> <span class="o">+</span> <span class="n">c_new</span> <span class="c1"># add the bigram to teh vocabulary
</span>	 	<span class="n">replace</span> <span class="n">each</span> <span class="n">occurence</span> <span class="n">of</span> <span class="n">c_left</span><span class="p">,</span> <span class="n">c_right</span> <span class="k">with</span> <span class="n">c_new</span> <span class="c1"># update the corpus
</span>	 <span class="nf">return</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></figure>

<p>Once the <strong>token learner</strong> learns the vocabulary, the <strong>token parser</strong> is used to tokenize a test sentence from teh learned tokens that were leraned from teh training data.</p>

<p>In real applications of BPE algorithms BPE is run with many thousands of merges such that most words are represented as tokens and only the rare words are represented by their parts.</p>

<p>Byte-Pair Encoding was originally a compression algorithm where we replace the most frequent byte pair with a new byte - thereby compressing the data.</p>

<p>For further reading check out this <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/slides/cs224n-2019-lecture12-subwords.pdf">NLP class slides from Stanford</a> or this <a href="https://web.stanford.edu/~jurafsky/slp3/2.pdf">chapter on Text Normalization from the Jurafsky and Martin Textbook</a></p>
<h2 id="references">References</h2>
<ul>
  <li>T. Kudo. Subword Regularization: <a href="https://arxiv.org/pdf/1804.10959.pdf">Improving Neural Network Translation Models with Multiple Subword Candidates</a>. 2018</li>
  <li>T. Kudo and J. Richardson. <a href="https://arxiv.org/pdf/1808.06226.pdf">SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing</a>. 2018</li>
  <li>M. Schuster and K. Nakajima. <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37842.pdf">Japanese and Korea Voice Search</a>. 2012</li>
  <li>R. Sennrich, B. Haddow and A. Birch. <a href="http://aclweb.org/anthology/P16-1162">Neural Machine Translation of Rare Words with Subword Units</a>. ACL 2016</li>
</ul>


            </div>
        </div>
        <!-- End Post -->

        <!-- Related posts list-->
        <aside class="col-md-3 flex-md-unordered">
            <div class="related-posts sticky-top sticky-top-offset">
    <p class="related">Related posts:</p>
    <ul>
        
            
                
                    <li><a href="/blog/2023/ml-to-llm/">Machine Learning, Deep Learning and Large Language Models</a></li>
                
            
        
            
                
                    <li><a href="/blog/2023/Important-books-for-AI/">Important books to read for AI</a></li>
                
            
        
            
                
                    <li><a href="/blog/2021/probability-theory/">Probability Theory for Natural Language Processing</a></li>
                
            
        
            
                
                    <li><a href="/blog/2021/language-models/">The Foundations of Language Models</a></li>
                
            
        
            
                
                    <li><a href="/blog/2021/logistic-regression/">The Comprehensive Guide to Logistic Regression</a></li>
                
            
        
            
                
                    <li class="active"><a href="/blog/2021/byte-pair-encoding/">What is Byte-Pair Encoding for Tokenization?</a></li>
                
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
                
                    <li><a href="/blog/2019/manageml/">Managing Machine Learning Experiments</a></li>
                
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
                
                    <li><a href="/blog/2017/what-is-nlp/">What is Natural Language Processing (NLP)?</a></li>
                
            
        
            
                
                    <li><a href="/blog/2016/NLP-ML/">Natural Language Processing vs. Machine Learning vs. Deep Learning</a></li>
                
            
        
            
                
                    <li><a href="/blog/2015/word2vec/">Online Word2Vec for Gensim</a></li>
                
            
        
            
                
                    <li><a href="/blog/2015/statistics-for-everyone/">Understanding your Data - Basic Statistics</a></li>
                
            
        
            
                
                    <li><a href="/blog/2014/all-about-that-bayes-intro-to-probability/">An Introduction to Probability</a></li>
                
            
        
            
                
                    <li><a href="/blog/2014/build-your-own-search-engine/">Build your own search Engine</a></li>
                
            
        
            
                
                    <li><a href="/blog/2014/core-of-lucene/">The Math behind Lucene</a></li>
                
            
        
    </ul>
</div>
        </aside>

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

    <div class="container">
        <div id="comments" class="row justify-content-center mb-5">
            <div class="col-md-8">
                <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'datasciencetoolbox'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

            </div>
        </div>
    </div>

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->



<script>
    // Load document before calculating window height
            var winHeight = $(window).height(),
                docHeight = $(document).height(),
                progressBar = $('#myBar'),
                max, value;

            /* Set the max scrollable area */
            max = docHeight - winHeight;
            //progressBar.attr('max', max);

            $(document).on('scroll', function () {
                value = $(window).scrollTop()/max;
                console.log(value);
                progressBar.attr('value', value);
            });
</script>
        </div>
    </div>

    <!-- Begin Footer
    ================================================== -->
    <footer class="footer">
        <div class="container">
            <div class="row">
                <div class="col-md-12 col-sm-12 text-center text-lg-center">
                    Copyright © 2023 Rutu Mulkar. All Rights Reserved.
                </div>
            </div>
        </div>
    </footer>
    <!-- End Footer
    ================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="/assets/js/mediumish.js"></script>



<script src="/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//datasciencetoolbox.disqus.com/count.js"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: 
        {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: false,
        }
        
    });
</script>

  
<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    CommonHTML: { linebreaks: { automatic: true } },
    "HTML-CSS": { scale: 100, linebreaks: { automatic: true } },
    TeX: { equationNumbers: {autoNumber: "all"} } });
</script>

<!-- Category filter -->
<script src="/assets/js/categorySearch.js"></script>
</body>
</html>
